---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Imports

```{python tags=c()}
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pyarrow.parquet as pq
from itertools import product
```

# Config

```{python}
DATA_FILE_PATHS = '/workspace/rahnemacollege/Project/Git/demand-prediction/data'
SHAPE_FILE_PATH = '/workspace/rahnemacollege/Project/Git/demand-prediction/map_data/taxi_zones/taxi_zones.shp'
start_date = '2023-03-31'
end_date = '2023-05-01'
```

# Load Data files

```{python}
def load_data(file_paths, start_date=None):
    df = pd.read_parquet(file_paths)
    df['date'] = df['tpep_pickup_datetime'].dt.date.astype(str)

    if start_date:
        df = df[df['date'] > start_date].reset_index(drop=True)

    return df


rides_df = load_data(DATA_FILE_PATHS, start_date)
print(rides_df.shape)
rides_df.head()
```

```{python}
def labeling(rides_df: pd.DataFrame):
    aggregated_df = rides_df.groupby(
        ['date', 'PULocationID']).size().reset_index(name='count')
    unique_dates = rides_df['date'].unique()
    unique_pu_location_ids = rides_df['PULocationID'].unique()
    all_combinations = list(product(unique_dates, unique_pu_location_ids))
    combinations_df = pd.DataFrame(all_combinations, columns=[
                                   'date', 'PULocationID'])
    label_df = aggregated_df.merge(combinations_df, how='right', on=[
                                   'date', 'PULocationID']).fillna(0)
    return label_df


labels_df = labeling(rides_df)
print(labels_df.shape)
labels_df.head()
```

### Improved Data Bound Within Range: 2023-04-01 to 2023-04-30

For Model Evaluation

```{python}
labels_df['date'] = pd.to_datetime(labels_df['date'])
```

```{python}
filtered_rides_df = labels_df[(labels_df['date'] >= start_date) & (
    labels_df['date'] < end_date)]
```

```{python}
# Sort the DataFrame based on the 'tpep_pickup_datetime' column in ascending order
filtered_rides_df = filtered_rides_df.sort_values(by='date')
```

```{python}
filtered_rides_df = filtered_rides_df.reset_index(drop=True)
```

```{python}
# Step 1: Generate random noise
noise = np.random.randint(0, 10, size=len(filtered_rides_df))

filtered_rides_df['pred_count'] = filtered_rides_df['count'] + noise
```

```{python tags=c()}
print(filtered_rides_df.shape)
filtered_rides_df.head()
```

```{python tags=c()}
# To handle the issue with MAPE and zero values in the count column, we replace zeros
# with the minimum non-zero count value. This prevents division by zero and ensures
# accurate evaluation of the metric.
min_non_zero_value = np.min(
    filtered_rides_df['count'][filtered_rides_df['count'] != 0])
filtered_rides_df.loc[filtered_rides_df['count']
                      == 0, 'count'] = min_non_zero_value
```

# Report by MAPE Metric


### Define MAPE Metric Function

```{python}
# Define the MAPE calculation function
def calculate_mape(actual, predicted):
    return (abs((actual - predicted) / actual)).mean() * 100


# Calculate MAPE
mape = calculate_mape(
    filtered_rides_df['count'], filtered_rides_df['pred_count'])
print("MAPE: {:.2f}%".format(mape))
```

### Calculate MAPE per LocationID

```{python}
def calculate_mape_locationID(df, Location_Col, LocationID):
    selected_df = df[df[Location_Col] == LocationID]
    actual = selected_df['count']
    predicted = selected_df['pred_count']
    mape = calculate_mape(actual, predicted)
    return mape
```

```{python}
locationID_mape = 2
mape_LocationID_output = calculate_mape_locationID(
    filtered_rides_df, 'PULocationID', locationID_mape)
print("MAPE for LocationID {}: {:.2f}%".format(
    locationID_mape, mape_LocationID_output))
```

### Calculate Average MAPE per all LocationIDs

```{python}
PULocationIDs = filtered_rides_df['PULocationID'].unique()
PULocationIDs.sort()
mape_all = []
for locationID in PULocationIDs:
    mape_location = calculate_mape_locationID(
        filtered_rides_df, 'PULocationID', locationID)
    mape_all.append({'LocationID': locationID, 'MAPE': mape_location})
PULocationIDs_MAPE = pd.DataFrame(mape_all)
AvgMAPE = sum(PULocationIDs_MAPE['MAPE'].values)/len(PULocationIDs)
print("Average MAPE per LocationIDs: {:.2f}%".format(mape))
```

## Visualization


### MAPE Metric on Map based on selected date

Zones (Borough): **EWR, Queens, Bronx, Manhattan, Staten Island, Brooklyn**

Date Range: **2023-04-01_2023-04-30**

```{python}
# This function shows MAPE metric on map based on selected date on month
# Becuase of to many locationIDs, we limited our visualization to each zone(Borough)
def visualize_mape_zone_date(zone, date, df):
    shape = gpd.read_file(SHAPE_FILE_PATH)
    counts_PU = df.rename(columns={'PULocationID': 'LocationID'})
    counts_PU = counts_PU[counts_PU['date'] == date]
    merged_gdf = shape.merge(counts_PU, on='LocationID', how='left')
    merged_gdf = merged_gdf.dropna()
    merged_gdf['MAPE'] = np.where(merged_gdf['count'] != 0, (abs(
        (merged_gdf['count'] - merged_gdf['pred_count']) / merged_gdf['count'])) * 100, 1)
    merged_gdf_selected = merged_gdf[merged_gdf['borough'] == zone]

    # Create a single plot
    fig, ax = plt.subplots(figsize=(10, 7.5))

    # Plot the map with 'MAPE' column
    merged_gdf_selected.plot(
        column='MAPE', cmap='Oranges_r', legend=True, ax=ax)
    ax.set_title('Prediction based on MAPE for selected date: {}'.format(date))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Annotate 'MAPE' values on the map
    for idx, row in merged_gdf_selected.iterrows():
        loc_mape = "{}\n{:.1f}%".format(row['LocationID'], row['MAPE'])
        x, y = row.geometry.centroid.x, row.geometry.centroid.y
        ax.text(x, y, str(loc_mape), fontsize=8,
                ha='center', va='center', color='black')

    plt.show()
```

```{python tags=c()}
visualize_mape_zone_date('Queens', '2023-04-01', filtered_rides_df)
```
