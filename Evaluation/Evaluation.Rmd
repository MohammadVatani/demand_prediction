---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region tags=[] -->
# Imports
<!-- #endregion -->

```{python tags=c()}
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pyarrow.parquet as pq
import seaborn as sns
from itertools import product
```

```{python}
# %matplotlib inline
```

# Config

```{python}
DATA_FILE_PATHS = '/workspace/rahnemacollege/Project/Git/demand-prediction/data'
SHAPE_FILE_PATH = '/workspace/rahnemacollege/Project/Git/demand-prediction/map_data/taxi_zones/taxi_zones.shp'
LR_PATH = '/workspace/rahnemacollege/Project/Git/demand-prediction/data/lr_result.parquet'
XGB_PATH = '/workspace/rahnemacollege/Project/Git/demand-prediction/data/XGB_result.parquet'

start_date_test = '2023-04-01'
end_date_test = '2023-05-01'
```

# Load Data files

```{python tags=c()}
def load_data(file_paths):
    df = pd.read_parquet(file_paths).reset_index()
    df = df.rename(columns={'real demand': 'count',
                   'predicted demand': 'pred_count'})
    return df
```

```{python}
lr_rides_df = load_data(LR_PATH)
print(lr_rides_df.shape)
lr_rides_df.head()
```

```{python}
xgb_rides_df = load_data(XGB_PATH)
print(xgb_rides_df.shape)
xgb_rides_df.head()
```

### Improved Data Bound Within Range: 2023-04-01 to 2023-04-30

For Model Evaluation

```{python tags=c()}
def df_time_bound(df):
    df['date'] = pd.to_datetime(df['date'])
    filtered_rides_df = df[(df['date'] >= start_date_test) & (
        df['date'] < end_date_test)]
    # Sort the DataFrame based on the 'tpep_pickup_datetime' column in ascending order
    filtered_rides_df = filtered_rides_df.sort_values(by='date')
    filtered_rides_df = filtered_rides_df.reset_index(drop=True)
    return filtered_rides_df
```

```{python tags=c()}
lr_rides_df = df_time_bound(lr_rides_df)
print(lr_rides_df.shape)
lr_rides_df.head()
```

```{python tags=c()}
xgb_rides_df = df_time_bound(xgb_rides_df)
print(xgb_rides_df.shape)
xgb_rides_df.head()
```

# Report by MAPE Metric


### Define MAPE Metric Function

```{python}
# Define the MAPE calculation function
def calculate_mape(actual, predicted):
    return (abs((actual - predicted) / actual)).mean() * 100


# Calculate MAPE
mape = calculate_mape(
    xgb_rides_df['count'], xgb_rides_df['pred_count'])
print("MAPE: {:.2f}%".format(mape))
```

### Calculate MAPE per LocationID

```{python}
def calculate_mape_locationID(df, Location_Col, LocationID):
    selected_df = df[df[Location_Col] == LocationID]
    actual = selected_df['count']
    predicted = selected_df['pred_count']
    mape = calculate_mape(actual, predicted)
    return mape
```

```{python}
locationID_mape = 2
mape_LocationID_output = calculate_mape_locationID(
    xgb_rides_df, 'PULocationID', locationID_mape)
print("MAPE for LocationID {}: {:.2f}%".format(
    locationID_mape, mape_LocationID_output))
```

### Calculate Average MAPE per all LocationIDs

```{python tags=c()}
PULocationIDs = xgb_rides_df['PULocationID'].unique()
PULocationIDs.sort()
mape_all = []
for locationID in PULocationIDs:
    mape_location = calculate_mape_locationID(
        xgb_rides_df, 'PULocationID', locationID)
    mape_all.append({'LocationID': locationID, 'MAPE': mape_location})


PULocationIDs_MAPE = pd.DataFrame(mape_all)
print(PULocationIDs_MAPE.shape)
print(PULocationIDs_MAPE.head())


AvgMAPE = sum(PULocationIDs_MAPE['MAPE'].values)/len(PULocationIDs)
print("Average MAPE per LocationIDs: {:.2f}%".format(mape))
```

<!-- #region tags=[] -->
## Visualization
<!-- #endregion -->

### MAPE Metric on Map based on selected date

Zones (Borough): **EWR, Queens, Bronx, Manhattan, Staten Island, Brooklyn**

Date Range: **2023-04-01_2023-04-30**

Lower is better based on MAPE Metric

```{python}
zones = ['EWR', 'Queens', 'Bronx', 'Manhattan', 'Staten Island', 'Brooklyn']
```

```{python}
# This function shows MAPE metric on map based on selected date of month

def visualize_mape_zone_date(zone, date, df):
    shape = gpd.read_file(SHAPE_FILE_PATH)
    counts_PU = df.rename(columns={'PULocationID': 'LocationID'})
    counts_PU = counts_PU[counts_PU['date'] == date]
    merged_gdf = shape.merge(counts_PU, on='LocationID', how='left')
    merged_gdf = merged_gdf.dropna()
    merged_gdf['MAPE'] = np.where(merged_gdf['count'] != 0, (abs(
        (merged_gdf['count'] - merged_gdf['pred_count']) / merged_gdf['count'])) * 100, 1)
    merged_gdf_selected = merged_gdf[merged_gdf['borough'] == zone]

    # Create a single plot
    fig, ax = plt.subplots(figsize=(10, 7.5))

    # Plot the map with 'MAPE' column
    merged_gdf_selected.plot(
        column='MAPE', cmap='Oranges_r', legend=True, ax=ax)
    ax.set_title(
        'Prediction based on MAPE for {} and selected date: {}'.format(zone, date))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Annotate 'MAPE' values on the map
    for idx, row in merged_gdf_selected.iterrows():
        loc_mape = "{}".format(row['LocationID'])
        x, y = row.geometry.centroid.x, row.geometry.centroid.y
        ax.text(x, y, str(loc_mape), fontsize=8,
                ha='center', va='center', color='black')

    plt.show()
```

```{python tags=c()}
# for i in zones:
#    visualize_mape_zone_date(i, '2023-04-01', xgb_rides_df)
```

<!-- #region tags=[] -->
### MAPE Metric on Map based on whole test data

Zones (Borough): **EWR, Queens, Bronx, Manhattan, Staten Island, Brooklyn**

Lower is better
<!-- #endregion -->

```{python tags=c()}
# This function shows MAPE metric on map based on whole test data
def visualize_mape_zone(zone, df):
    shape = gpd.read_file(SHAPE_FILE_PATH)
    counts_PU = df.rename(
        columns={'PULocationID': 'LocationID'})
    merged_gdf = shape.merge(counts_PU, on='LocationID', how='left')
    merged_gdf = merged_gdf.dropna()
    merged_gdf_selected = merged_gdf[merged_gdf['borough'] == zone]

    # Create a single plot
    fig, ax = plt.subplots(figsize=(10, 7.5))

    # Plot the map with 'count' column
    # Reverse the colormap by setting vmin and vmax to reverse the values
    merged_gdf_selected.plot(
        column='MAPE', cmap='Oranges_r', legend=True, ax=ax)
    ax.set_title('Prediction based on MAPE for {}'.format(zone))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Annotate 'MAPE' values on the map
    for idx, row in merged_gdf_selected.iterrows():
        location_id = "{}".format(row['LocationID'])
        x, y = row.geometry.centroid.x, row.geometry.centroid.y
        ax.text(x, y, str(location_id), fontsize=8,
                ha='center', va='center', color='black')

    plt.show()
```

```{python tags=c()}
for i in zones:
    visualize_mape_zone(i, PULocationIDs_MAPE)
```

### Predicted demand on whole test data

Zones (Borough): **EWR, Queens, Bronx, Manhattan, Staten Island, Brooklyn**

```{python}
def visualize_demand_zone(zone, df, col_show):
    shape = gpd.read_file(SHAPE_FILE_PATH)
    counts_PU = df.rename(columns={'PULocationID': 'LocationID'})
    counts_PU = counts_PU.groupby('LocationID')[['last_day_demand', 'count', 'pred_count']].sum(
    ).sort_values(col_show, ascending=False).reset_index()
    merged_gdf = shape.merge(counts_PU, on='LocationID', how='left')
    merged_gdf = merged_gdf.dropna()
    merged_gdf_selected = merged_gdf[merged_gdf['borough'] == zone]

    # Create a single plot
    fig, ax = plt.subplots(figsize=(10, 7.5))

    # Plot the map with 'MAPE' column
    merged_gdf_selected.plot(
        column='count', cmap='Oranges', legend=True, ax=ax)
    ax.set_title('{} of demands Zone: {}'.format(col_show, zone))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Annotate 'MAPE' values on the map
    for idx, row in merged_gdf_selected.iterrows():
        loc_mape = "{}".format(row['LocationID'])
        x, y = row.geometry.centroid.x, row.geometry.centroid.y
        ax.text(x, y, str(loc_mape), fontsize=8,
                ha='center', va='center', color='black')

    plt.show()
```

```{python}
for i in zones:
    visualize_demand_zone(i, xgb_rides_df, 'count')
```

```{python}
for i in zones:
    visualize_demand_zone(i, xgb_rides_df, 'pred_count')
```

<!-- #region tags=[] -->
## Cumulative Histogram
<!-- #endregion -->

### Compare Models prediction vs. Last day count base on MAPE metric

```{python}
def compare_models(model1, model2, lower_bound=0, upper_bound=262):
    xgb = model1.groupby('PULocationID')[['last_day_demand', 'count', 'pred_count']].sum(
    ).sort_values('count', ascending=False).reset_index()
    xgb['MAPE'] = ((abs(xgb['count'] - xgb['pred_count']) / xgb['count'])*100)
    xgb['MAPE_lastday'] = (
        (abs(xgb['count'] - xgb['last_day_demand']) / xgb['count'])*100)

    lr = model2.groupby('PULocationID')[['last_day_demand', 'count', 'pred_count']].sum(
    ).sort_values('count', ascending=False).reset_index()
    lr['MAPE'] = ((abs(lr['count'] - lr['pred_count']) / lr['count'])*100)
    lr['MAPE_lastday'] = (
        (abs(lr['count'] - lr['last_day_demand']) / lr['count'])*100)

    selected_df = xgb.iloc[lower_bound:upper_bound]
    selected_df1 = lr.iloc[lower_bound:upper_bound]

    plt.figure(figsize=(20, 5))
    plt.title('Count demand of LocationIDs Compare Models vs. Last day count')

    plt.plot(selected_df['MAPE'], label="MAPE Of XGB")
    plt.plot(selected_df1['MAPE'], label="MAPE Of Linear Regression")
    plt.plot(selected_df['MAPE_lastday'], label="MAPE Of LastDay")

    plt.xticks(selected_df.index, selected_df['PULocationID'], rotation=90)

    plt.legend()
    plt.xlabel('LocationID')
    plt.ylabel('Percetage MAPE%')

    plt.show()
```

```{python}
for i in range(0, 250, 50):
    if i == 0:
        compare_models(xgb_rides_df, lr_rides_df, i, i+50)
    else:
        compare_models(xgb_rides_df, lr_rides_df, i-15, i+35)
```

### Compare Models predicion vs. Last day count based on actual count

```{python}
def compare_model_scatter(model1, model2, lower_bound=0, upper_bound=262):
    xgb = model1.groupby('PULocationID')[['last_day_demand', 'count', 'pred_count']].sum(
    ).sort_values('count', ascending=False).reset_index()

    lr = model2.groupby('PULocationID')[['last_day_demand', 'count', 'pred_count']].sum(
    ).sort_values('count', ascending=False).reset_index()

    selected_df = xgb.iloc[lower_bound:upper_bound]
    selected_df1 = lr.iloc[lower_bound:upper_bound]

    plt.figure(figsize=(15, 5))
    plt.scatter(selected_df.index,
                selected_df['count'], label="Actual", color='red', s=15)
    plt.plot(selected_df.index, selected_df['pred_count'], label="XGB")
    plt.plot(selected_df.index, selected_df1['pred_count'], label="LR")
    plt.plot(selected_df.index,
             selected_df1['last_day_demand'], label="Last day")

    plt.xticks(selected_df.index, selected_df['PULocationID'], rotation=90)

    plt.legend()
    plt.xlabel('Index')
    plt.ylabel('Counts')
    plt.title('Demand count Compare XGBoost Model vs Last day')

    plt.show()
```

```{python}
for i in range(0, 250, 50):
    if i == 0:
        compare_model_scatter(xgb_rides_df, lr_rides_df, i, i+50)
    else:
        compare_model_scatter(xgb_rides_df, lr_rides_df, i-15, i+35)
```
