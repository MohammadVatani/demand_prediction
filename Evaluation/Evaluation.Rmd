---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Import Required Libraries

```{python tags=c()}
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pyarrow.parquet as pq
from itertools import product
```

# Load Data files

```{python}
DATA_FILE_PATHS = '/workspace/rahnemacollege/Project/Git/demand-prediction/data'
start_date = pd.to_datetime('2023-04-01 00:00:00')
end_date = pd.to_datetime('2023-05-01 00:00:00')
```

```{python}
def load_data(file_paths, start_date=None):
    df = pd.read_parquet(file_paths)
    df['date'] = df['tpep_pickup_datetime'].dt.date.astype(str)

    if start_date:
        df = df[df['date'] > start_date].reset_index(drop=True)

    return df


rides_df = load_data(DATA_FILE_PATHS, '2023-01-01')
print(rides_df.shape)
rides_df.head()
```

```{python}
def labeling(rides_df: pd.DataFrame):
    aggregated_df = rides_df.groupby(
        ['date', 'PULocationID']).size().reset_index(name='count')
    unique_dates = rides_df['date'].unique()
    unique_pu_location_ids = rides_df['PULocationID'].unique()
    all_combinations = list(product(unique_dates, unique_pu_location_ids))
    combinations_df = pd.DataFrame(all_combinations, columns=[
                                   'date', 'PULocationID'])
    label_df = aggregated_df.merge(combinations_df, how='right', on=[
                                   'date', 'PULocationID']).fillna(0)
    return label_df


labels_df = labeling(rides_df)
print(labels_df.shape)
labels_df.head()
```

### Improved Data Bound Within Range: 2023-04-01 to 2023-04-30

For Testing Purpose

```{python}
labels_df['date'] = pd.to_datetime(labels_df['date'])
```

```{python}
filtered_rides_df = labels_df[(labels_df['date'] >= start_date) & (
    labels_df['date'] < end_date)]
```

```{python}
# Sort the DataFrame based on the 'tpep_pickup_datetime' column in ascending order
filtered_rides_df = filtered_rides_df.sort_values(by='date')
```

```{python}
filtered_rides_df = filtered_rides_df.reset_index(drop=True)
```

```{python}
filtered_rides_df['pred_count'] = filtered_rides_df['count']
```

```{python tags=c()}
filtered_rides_df.head(10)
```

# Report by MAPE Metric


### Define MAPE Metric Function

```{python}
# Define the MAPE calculation function
def calculate_mape(actual, predicted):
    if np.all(actual == 0):
        return 0.0
    return (abs((actual - predicted) / actual)).mean() * 100


# Calculate MAPE
mape = calculate_mape(
    filtered_rides_df['count'], filtered_rides_df['pred_count'])
print("MAPE: {:.2f}%".format(mape))
```

### Calculate MAPE per LocationID

```{python}
def calculate_mape_locationID(df, PULocationID):
    selected_df = df[df['PULocationID'] == PULocationID]
    actual = selected_df['count']
    predicted = selected_df['pred_count']
    mape = calculate_mape(actual, predicted)
    return mape
```

```{python}
locationID_mape = 263
calculate_mape_locationID(filtered_rides_df, locationID_mape)
print("MAPE for LocationID {}: {:.2f}%".format(locationID_mape, mape))
```

### Calculate Average MAPE per all LocationIDs

```{python}
PULocationIDs = filtered_rides_df['PULocationID'].unique()
PULocationIDs.sort()
for locationID in PULocationIDs:
    mape_all = []
    mape_all.append(calculate_mape_locationID(filtered_rides_df, locationID))
    AvgMAPE = sum(mape_all)/len(PULocationIDs)

print("Average MAPE per LocationIDs: {:.2f}%".format(mape))
```

## Visualization

Zones (Borough): **EWR, Queens, Bronx, Manhattan, Staten Island, Brooklyn**

Date Range: **2023-04-01_2023-04-30**

```{python}
# This Function shows demand on map based on selected date on month
# Becuase of to many locationIDs, we limited our visualization to each zone(Borough)
def visualize_mape_zone_date(zone, date, df):
    shape = gpd.read_file(
        '/workspace/rahnemacollege/Project/Git/demand-prediction/map_data/taxi_zones/taxi_zones.shp')
    counts_PU = df.rename(columns={'PULocationID': 'LocationID'})
    counts_PU = counts_PU[counts_PU['date'] == date]
    merged_gdf = shape.merge(counts_PU, on='LocationID', how='left')
    merged_gdf = merged_gdf.dropna()
    merged_gdf['MAPE'] = np.where(merged_gdf['count'] != 0, (abs(
        (merged_gdf['count'] - merged_gdf['pred_count']) / merged_gdf['count'])) * 100, 0)
    merged_gdf_selected = merged_gdf[merged_gdf['borough'] == zone]

    # Create a single plot
    fig, ax = plt.subplots(figsize=(10, 7.5))

    # Plot the map with 'count' column
    # Reverse the colormap by setting vmin and vmax to reverse the values
    merged_gdf_selected.plot(column='MAPE', cmap='Oranges_r', legend=True, ax=ax,
                             vmin=merged_gdf_selected['MAPE'].max(), vmax=merged_gdf_selected['MAPE'].min())
    ax.set_title('Prediction based on MAPE')
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Annotate 'MAPE' values on the map
    for idx, row in merged_gdf_selected.iterrows():
        location_id = row['MAPE']
        x, y = row.geometry.centroid.x, row.geometry.centroid.y
        ax.text(x, y, str(location_id), fontsize=8,
                ha='center', va='center', color='black')

    plt.show()
```

```{python tags=c()}
visualize_mape_zone_date('Queens', '2023-04-01', filtered_rides_df)
```
